{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wtuOIo0HAP5v","executionInfo":{"status":"ok","timestamp":1683090557232,"user_tz":-330,"elapsed":581,"user":{"displayName":"Dharmendra MNNIT","userId":"06352044623593572690"}},"outputId":"302e31d4-6646-4177-f441-2698aadad595"},"outputs":[{"output_type":"stream","name":"stdout","text":["('eggs',) -> ('bread', 'diapers') (support = 0.20, confidence = 1.00, lift = 5.00)\n","('bread', 'diapers') -> ('eggs',) (support = 0.20, confidence = 1.00, lift = 5.00)\n","('milk', 'diapers') -> ('cheese', 'vegetables') (support = 0.20, confidence = 1.00, lift = 2.50)\n","('eggs',) -> ('diapers',) (support = 0.20, confidence = 1.00, lift = 1.67)\n","('eggs',) -> ('bread',) (support = 0.20, confidence = 1.00, lift = 1.67)\n","('diapers',) -> ('cheese', 'vegetables') (support = 0.60, confidence = 0.67, lift = 1.67)\n","('cheese',) -> ('diapers', 'vegetables') (support = 0.60, confidence = 0.67, lift = 1.67)\n","('vegetables',) -> ('cheese', 'diapers') (support = 0.60, confidence = 0.67, lift = 1.67)\n","('diapers', 'cheese') -> ('vegetables',) (support = 0.40, confidence = 1.00, lift = 1.67)\n","('diapers', 'vegetables') -> ('cheese',) (support = 0.40, confidence = 1.00, lift = 1.67)\n","('cheese', 'vegetables') -> ('diapers',) (support = 0.40, confidence = 1.00, lift = 1.67)\n","('milk', 'diapers') -> ('vegetables',) (support = 0.20, confidence = 1.00, lift = 1.67)\n","('bread', 'eggs') -> ('diapers',) (support = 0.20, confidence = 1.00, lift = 1.67)\n","('diapers', 'eggs') -> ('bread',) (support = 0.20, confidence = 1.00, lift = 1.67)\n","('milk', 'diapers') -> ('cheese',) (support = 0.20, confidence = 1.00, lift = 1.67)\n","('bread', 'vegetables') -> ('milk',) (support = 0.20, confidence = 1.00, lift = 1.67)\n","('bread', 'cheese') -> ('milk',) (support = 0.20, confidence = 1.00, lift = 1.67)\n","('milk', 'diapers', 'cheese') -> ('vegetables',) (support = 0.20, confidence = 1.00, lift = 1.67)\n","('milk', 'diapers', 'vegetables') -> ('cheese',) (support = 0.20, confidence = 1.00, lift = 1.67)\n","('milk', 'cheese', 'vegetables') -> ('diapers',) (support = 0.20, confidence = 1.00, lift = 1.67)\n","('diapers',) -> ('cheese',) (support = 0.60, confidence = 0.67, lift = 1.11)\n","('cheese',) -> ('diapers',) (support = 0.60, confidence = 0.67, lift = 1.11)\n","('milk',) -> ('vegetables',) (support = 0.60, confidence = 0.67, lift = 1.11)\n","('vegetables',) -> ('milk',) (support = 0.60, confidence = 0.67, lift = 1.11)\n","('milk',) -> ('cheese',) (support = 0.60, confidence = 0.67, lift = 1.11)\n","('cheese',) -> ('milk',) (support = 0.60, confidence = 0.67, lift = 1.11)\n","('cheese',) -> ('vegetables',) (support = 0.60, confidence = 0.67, lift = 1.11)\n","('vegetables',) -> ('cheese',) (support = 0.60, confidence = 0.67, lift = 1.11)\n","('bread',) -> ('milk',) (support = 0.60, confidence = 0.67, lift = 1.11)\n","('milk',) -> ('bread',) (support = 0.60, confidence = 0.67, lift = 1.11)\n","('diapers',) -> ('vegetables',) (support = 0.60, confidence = 0.67, lift = 1.11)\n","('vegetables',) -> ('diapers',) (support = 0.60, confidence = 0.67, lift = 1.11)\n"]}],"source":["import itertools\n","\n","# Define the dataset\n","dataset = [\n","    ['bread', 'milk', 'vegetables'],\n","    ['bread', 'milk', 'cheese'],\n","    ['bread', 'diapers', 'eggs'],\n","    ['milk', 'diapers', 'cheese', 'vegetables'],\n","    ['diapers', 'cheese', 'vegetables']\n","]\n","\n","# Set the minimum support and confidence\n","min_support = 0.2\n","min_confidence = 0.6\n","\n","# Create candidate itemsets of length k from the dataset\n","def create_candidate_itemsets(dataset, k):\n","    candidate_itemsets = set()\n","    for transaction in dataset:\n","        for itemset in itertools.combinations(transaction, k):\n","            candidate_itemsets.add(itemset)\n","    return candidate_itemsets\n","\n","# Calculate the support of an itemset in the dataset\n","def support(itemset):\n","    count = 0\n","    for transaction in dataset:\n","        if set(itemset).issubset(set(transaction)):\n","            count += 1\n","    return count / len(dataset)\n","\n","# Generate frequent itemsets using the Apriori algorithm\n","def apriori(dataset):\n","    frequent_itemsets = []\n","    k = 1\n","    while True:\n","        candidate_itemsets = create_candidate_itemsets(dataset, k)\n","        frequent_itemsets_k = []\n","        for itemset in candidate_itemsets:\n","            itemset_support = support(itemset)\n","            if itemset_support >= min_support:\n","                frequent_itemsets_k.append((itemset, itemset_support))\n","        if not frequent_itemsets_k:\n","            break\n","        frequent_itemsets.extend(frequent_itemsets_k)\n","        k += 1\n","    return frequent_itemsets\n","\n","frequent_itemsets = apriori(dataset)\n","\n","# Generate association rules from frequent itemsets\n","def generate_association_rules(frequent_itemsets):\n","    association_rules = []\n","    for itemset, itemset_support in frequent_itemsets:\n","        for k in range(1, len(itemset)):\n","            for antecedent in itertools.combinations(itemset, k):\n","                antecedent_support = support(antecedent)\n","                consequent = tuple(sorted(set(itemset) - set(antecedent)))\n","                consequent_support = support(consequent)\n","                if antecedent_support >= min_support and consequent_support >= min_support:\n","                    rule_support = antecedent_support\n","                    rule_confidence = itemset_support / antecedent_support\n","                    rule_lift = rule_confidence / consequent_support\n","                    if rule_confidence >= min_confidence:\n","                        association_rules.append((antecedent, consequent, rule_support, rule_confidence, rule_lift))\n","    return association_rules\n","\n","association_rules = generate_association_rules(frequent_itemsets)\n","\n","# Sort the association rules by decreasing lift\n","association_rules = sorted(association_rules, key=lambda x: x[4], reverse=True)\n","\n","# Print the association rules\n","for rule in association_rules:\n","    print(f\"{rule[0]} -> {rule[1]} (support = {rule[2]:.2f}, confidence = {rule[3]:.2f}, lift = {rule[4]:.2f})\")\n"]}]}